% !TEX root = ../thesis.tex

\chapter{Localization Framework}
\label{ch.Framework}

\section{Overview}
\label{framework.Overview}

This thesis introduces a method to use sonar imagery for position localization with respect to a seafloor topography map.
Specifically, acoustic shadows in sonar imagery are used, due to the primarily geometric nature of acoustic shadows, as discussed in Section \ref{intro.Sonar.Acoustic}.

This chapter describes the localization framework.  
Section \ref{framework.Underwater} introduces the underwater position localization problem.  
Estimated and measured vehicle pose states are described, along with the representation of underwater position. Section \ref{framework.Bayesian} provides an introductory overview to Bayesian estimation, with specific applicability to the underwater localization problem.  
The concepts of measurement updates and motion/time updates are introduced.  

The Bayesian measurement update for the use of acoustic shadows in sonar imagery is the major contribution of this work, and is introduced in Section \ref{framework.Measurement}.
The measurement update is usable for any Bayesian estimator that does not require a linearized measurement model. 
The highly non-linear nature of the measurement update makes it ill-suited to Gaussian estimators that require measurement linearization, such as the Extended Kalman Filter (EKF).
Examples of Bayesian estimators that do not require measurement model linearization include non-parametric filters such as Particle Filters and Point Mass Filters, along with Gaussian estimators such as the Unscented Kalman Filter (UKF).
Toward describing the measurement update, three sub-sections provide details of the measurement update process.
Section \ref{framework.Measurement.Measured} details the labeling of acoustic shadows in measured sonar imagery.
Section \ref{framework.Measurement.Expected} provides an overview of the expected signal generation process, where for this work the expected signal is a probabilistic visibility image in the sonar image domain.
The main details of expected signal generation through the use of a visibility measurement model are left to Chapter \ref{ch.MeasurementModel}.
Finally, Section \ref{framework.Measurement.Weighting} presents the measurement weighting function used to provide the measurement update.

Section \ref{framework.PMF} describes the Point Mass Filter (PMF), which is a specific type of Bayesian estimator used in this work. 
The reasons for the choice of PMF as the specific non-parametric estimator used are provided.
PMF intialization, motion/time updates, and measurement updates are detailed.
Further, PMF implementation differences for two vehicle operational cases are presented: (1) the motionless case where sonar imagery is collected while the underwater vehicle does not move, which is suitable for ROV or hover-capable AUV use, and (2) the case with vehicle motion while sonar imagery data is collected, which is suitable for general AUV operation.

In order to provide precision position estimation without significant computatioal overhead, multi-resolution estimation is employed in this work.
Initially, discrete state estimates are populated at a coarse resolution.
Additional discrete state estimates are populated about coarse resolution estimates that are successful (highly weighted by the PMF estimator).
This enables high-precision estimation in areas of the state space that are likely position candidates.
Methods for multi-resolution refinement of the PMF are presented in Section \ref{framework.PMF.Multi}.

Finally, Section \ref{framework.Statistics} provides estimator summary statistics and tools for automatic analyses of results.  
%In particular, a method to quantify the amount of information content in the expected measurements is presented as a means of evaluating 

\section{The Underwater Localization Problem}
\label{framework.Underwater}

This work enables map-relative, 2-DOF horizontal position estimation for underwater vehicles using sonar imagery.  As such, horizontal position is the estimata state vector.  The four remaining vehicle pose states (vertical position and 3-DOF attitude/orientation) are treated as measured quantities.

Vertical position is measured both in an absolute and in a terrain-relative sense.
Pressure sensors accurately measure absolute depth relative to the water surface.
Altitude, as measured directly by an altimeter or by using the ranges of the four beams of a DVL, provides a map-relative vertical position.

Vehicle attitude is similarly treated as a measured quantity.
Attitude may be measured by an IMU, AHRS, or INS, as discussed in Section \ref{intro.Existing.Dead}.

Table \ref{tab:states} summarizes vehicle pose state symbols, physical description, and method of calculation for this work (estimated or measured).

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Symbol} & \textbf{Quantity} & \textbf{Calculation} \\ \hline
$x_E$ & Eastings horizontal position & Estimated \\ \hline
$x_N$ & Nortings horizontal position & Estimated \\ \hline
$z$ & Depth & Measured \\ \hline
$a$ & Altitude & Measured \\ \hline
$\boldsymbol{\theta}$ & 3-DOF Attitude & Measured \\ \hline
\end{tabular}
\caption{Table of vehicle states. 2-D horizontal position is the estimated state vector. Vertical position is measured in absolute terms as depth, and in map-relative terms as altitude. 3-DOF Attitude is measured by an IMU, AHRS, or INS.}
\label{tab:states}
\end{table}

Horizontal position on the Earth is generally expressed in one of two ways: (1) as latitude and longitude expressed in angular units (e.g. degrees), or (2) as Northings and Eastings in a projected Cartesian coordinate system, expressed as metric distances.
The representation of position in longitude and latitude has the advantage that it is a true representation of position on the Earth, but has the disadvantage that these quantities are in angular units.
Representing translational quantities in terms of angular differences is awkward.

Projected coordinate systems represent position as local East (Eastings) and local North (Northings) distances relative to a horizontal datum, usually expressed in meters. 
A common projected coordinate system is the Universal Transverse Mercator coordinate system (UTM), which subdivides the Earth into unique zones that are $6^{o}$ wide in longitude and $8^{o}$ wide in latitude, with a local Eastings/Northings Cartesian grid for each zone, as shown in Figure \ref{fig:UTM}.

\begin{figure}[!h]
	\centering
		\includegraphics[width=1.0\textwidth]{Utm-zones}
	\caption{The UTM grid. Image courtesy Jan Krymmel. }
	\label{fig:UTM}
\end{figure}

In this work, estimated map-relative horizontal positions will be represented as local Northings and Eastings Cartesian coordinates relative to a latitude/longitude datum.  
The datum will typically be the best \emph{a priori} vehicle position estimate.
In the context of AUV operations, this datum is typically supplied by the integrated position estimate from an INS.
In the context of ROV operaitons, this datum is typically supplied by a USBL system, as described in Section \ref{intro.Existing.Acoustic.USBL}.

\section{Bayesian Estimation}
\label{framework.Bayesian}

Bayesian estimation is ubiquitous in the field of state estimation.  
In Bayesian estimation, states and measurements are modeled as random variables.
The posterior state distribution conditioned on all measurements, $p(\textbf{s}_k|\mathbb{Z}_k)$, is modeled as the product of the probability of the current measurement conditioned on the current state and the probability of the current state conditioned on all past measurements by exploiting Bayes rule:

\begin{align}
\begin{split}
p(\textbf{s}_k|\mathbb{Z}_k) &= \frac{p(\textbf{z}_k | \textbf{s}_k, \mathbb{Z}_{k-1})p(\textbf{s}_k | \mathbb{Z}_{k-1})}{p(\textbf{z}_k | \mathbb{Z}_{k-1})} \\
&= \eta p(\textbf{z}_k | \textbf{s}_k)p(\textbf{s}_k | \mathbb{Z}_{k-1}) \\
&= \eta p(\textbf{z}_k | \textbf{s}_k)p(\textbf{s}_k | \textbf{s}_{k-1})p(\textbf{s}_{k-1}|\mathbb{Z}_{k-1}) \\
\end{split}
\label{eq:Bayes}
\end{align}

\noindent where $\textbf{s}_k$ is the estimated state vector at timestep $k$, $\textbf{z}_k$ is the measurement vector at timestep $k$, and $\mathbb{Z}_k$ is the set of measurements from timesteps $1$ through $k$.  

The second line of Equation \ref{eq:Bayes} is derived from the first line according to: (1) the Markov assumption of state completeness, and (2) the property that the sum of a probability distribution over the entire domain is equal to one.
The assumption of state completeness implies that $p(\textbf{z}_k | \textbf{s}_k, \mathbb{Z}_{k-1}) = p(\textbf{z}_k | \textbf{s}_k)$, as the current state has all of the information encoded by past measurements.
The property of the distribution summing to one allows the replacement of $p(\textbf{z}_k | \mathbb{Z}_{k-1})$ with a normalization constant $\eta$, as this term does not depend on the state $\textbf{s}_k$. 
%The property of the distribution summing to one allows the replacement of $p(\textbf{z}_k | \mathbb{Z}_{k-1})$ with a normalization constant $\eta$, as this term does not depend on the state $\textbf{s}_k$, but is instead obtained by summing probabilities over the state domain:
%
%\begin{align}
%\begin{split}
%\eta \equiv p(\textbf{z}_k | \mathbb{Z}_{k-1}) &= \int_{\textbf{s}_k} p(\textbf{z}_k | \textbf{s}_k, \mathbb{Z}_{k-1}) d \textbf{s}_k \\
%&= \int_{\textbf{s}_k} p(\textbf{z}_k | \textbf{s}_k) d \textbf{s}_k
%\end{split}
%\label{eq:bayesNormalization}
%\end{align}

The third line of Equation \ref{eq:Bayes} shows the factorization of the state posterior distribution as a product of a measurement update, motion/time update, the previous timestep posterior state distribution.  The last term established the recursive nature of Bayesian estimation that allows for incremental state updates.  

Bayesian estimators split state estimation into the product of a measurement update and a motion/time update according to Equation \ref{eq:Bayes}.
The measurement update is represented by the first term in Equation \ref{eq:Bayes}, $p(\textbf{z}_k | \textbf{s}_k)$.
The measurment update is how the current measurement influences the state estimate.
The time (or motion) update is represented by the second term in \ref{eq:Bayes}.
The time update models the transition probability across timesteps.
Measurement and time updates are derived from system state equations, which can be generically expressed for the underwater localization problem as:

\begin{equation}
\mathbf{s}_k = g(\mathbf{s}_{k-1}, \mathbf{u}_k, \mathbf{w}_k)
\label{eq:genericMotionEquation}
\end{equation}
\begin{equation}
\mathbf{z}_k = h(\mathbf{s}_k, m, \mathbf{v}_k)
\label{eq:genericMeasurementEquation}
\end{equation}

\noindent where $\mathbf{u}_k$ is the INS inertial navigation estimate between timesteps $k-1$ and $k$, $\mathbf{w}_k$ is motion noise, $m$ is the seafloor terrain map, and $\mathbf{v}_k$ is measurement noise. 
The function $g()$ is known as a \emph{motion model}.  
The function $h()$ is known as a \emph{measurement model}. 
A major contribution of this work is the development of a probabilistic measurement model for the use of sonar imagery for position localization with respect to a topography map.

Bayesian estimation may be accomplished recursively or in batch.  
Batch estimation exploits the factorization of Equation \ref{eq:Bayes} to calculate the posterior distribution estimate for all timesteps at once, i.e. in batch.
Typically, this is formulated as a non-linear optimization where the objective function is derived from the  logarithm of the posterior state probability distribution:

\begin{align}
\begin{split}
\mathbf{s}_0^*, \mathbf{s}_1^*, \hdots, \mathbf{s}_K^* &= \underset{\mathbf{s}_0, \mathbf{s}_1, \hdots, \mathbf{s}_K}{\text{argmax}} \hspace{1ex}  \text{log} \hspace{0.4ex} p(\mathbf{s}_0) + \sum_{k=1}^{K} \text{log} \hspace{0.4ex} p(\mathbf{z}_k | \mathbf{s}_k) + \text{log} \hspace{0.4ex} p(\mathbf{s}_k | \mathbf{s}_{k-1})
\end{split}
\label{eq:batchBayes}
\end{align}

In the context of batch localization or simultaneous localization and mapping (SLAM), there are many names and implementations of this general approach [CITE SAM, iSAM, GraphSLAM stuff].  The terms Smoothing and Mapping (SAM) and GraphSLAM are often used to describe this family of methods.

Recursive Bayesian estimation exploits the recursive nature of Equation \ref{eq:Bayes} for incremental state estimate updates.
The canonical Bayesian estimator is the Kalman Filter [CITE KALMAN FILTER].
Recursive Bayesian estimators update the state estimate through the repeated steps of time and measuremnt updates. 
For posiiton localization of an underwater vehicle, these steps are generically summarized below.
\\ \\
\textbf{Time Update}. Evaluate $p(\mathbf{s}_k | \mathbf{s}_{k-1})$ by propagating the vehicle translational and rotational motion from timestep $k-1$ to $k$ by the motion model $g(\mathbf{s}_{k-1}, \mathbf{u}_k, \mathbf{w}_k)$ from Equation \ref{eq:genericMotionEquation}. 
\\ \\
\textbf{Measurement Update}. Calculate the posterior distribution $p(\textbf{s}_k|\mathbb{Z}_k)$ for timestep $k$ through the evaluation of $p(\mathbf{z}_k | \mathbf{s}_{k})$, using the measurement model $h(\mathbf{z}_k | \mathbf{s}_k, m, \mathbf{v}_k)$ from Equation \ref{eq:genericMeasurementEquation}, and normalization to form a valid probability distribution.
\\ \\
Recursive Bayesian estimators may be classified broadly as either Gaussian or non-parametric.
Gaussian estimators assume that the posterior state distribution is normally distributed.
The Kalman Filter and all of its variants (Extended Kalman Filter (EKF), Unscented Kalman Filter (UKF), and Information Filter) are Gaussian estimators.  

Non-parametric Bayesian estimators do not assume a functional form for the posterior state distribution.
Instead, non-parametric filters populate discrete state estimates to model the underlying state distribution.
Examples of non-parametric filters include Particle Filters (PFs) and Point Mass Filters (PMFs).

A feature of non-parametric state estimation especially useful for underwater navigation is that multi-modal distributions can be estimated, as opposed to Gaussian estimators that enforce a uni-modal normal form in modeling the underlying distribution.
The self-similarity of seafloor terrain can lead to multi-modal position distributions, which is well-handled by non-parametric estimators.
An issue with the use of non-parametric state estimation is that they can become computationally burdensome as the size of the state space grows.
In general, the computational burden of a non-parametric filter grows exponentially in the number of states estimated.

A main contribution of this thesis is the development of a measurement update $p(\mathbf{z}_k | \mathbf{s}_k)$  for the use of sonar imagery for underwater localization, and this measurement update can be used with any Bayesian estimator that does not require measurement model linearization.
Examples of recursive Bayesian estimators that do not require measurement model linearization are non-parametric filters such as Particle Filters and Point Mass Filters, and Gaussian estimators that do not require linearization such as the Unscented Kalman Filter (or Sigma Point Filter).
Further, the measurement model could be used in batch estimation methods that do not require measurement model linearization.
The measurement update introduced in this work is overviewed in Section \ref{framework.Measurement}.

\section{Measurement Update for Acoustic Shadows in Sonar Imagery}
\label{framework.Measurement}

This section provides an overview for the Bayesian measurement update for the use of acoustic shadows in sonar imagery for position localization.
The measurement update is usable for any Bayesian estimator that does not require a linearized measurement model. 
Examples of Bayesian estimators that do not require measurement model linearization include non-parametric filters such as Particle Filters and Point Mass Filters, along with Gaussian estimators such as the Unscented Kalman Filter (UKF).

Toward describing the measurement update, the following three sub-sections provide details of the measurement update process.
Section \ref{framework.Measurement.Expected} provides an overview of the expected signal generation process, where for this work the expected signal is a probabilistic visibility image in the sonar image domain.
The main details of expected signal generation through the use of a newly developed visibility measurement model are left to Chapter \ref{ch.MeasurementModel}.
Section \ref{framework.Measurement.Measured} details the labeling of acoustic shadows in measured sonar imagery.
Finally, Section \ref{framework.Measurement.Weighting} presents the measurement weighting function used to provide the measurement update $p(\mathbf{z}_k | \mathbf{s}_k)$.

\subsection{Expected Measurement Calculation}
\label{framework.Measurement.Expected}

Bayesian estimation relies on the comparison of actual measurements with expected measurements, where the latter are generated by use of a \emph{measurement model}.  
The following equation generically describes a measurement model for pose localization with respect to a topography map:

\begin{equation}
\tilde{\mathbf{z}}_k = h(\mathbf{s}_k, m, \mathbf{w}_k)
\label{eq:genericMeasurementModel}
\end{equation}

\noindent where $\mathbf{s}_k$ is the vehicle pose at time $k$, $m$ is a topography map, $\tilde{\mathbf{z}}_k$ is an expected measurement for timestep $k$, $\mathbf{w}_k$ is measurement noise, and $h()$ is a measurement model.

For the use of acoustic shadow data in sonar imagery, the expected measurement is a probabilistic visbility image.
For each vehicle pose hypothesis $i$ at timestep $k$ an expected visibility image, $P_k^{i}$, is generated, where each pixel in the image represents the probability that this pixel in the measured image is visible, i.e. is \emph{not} in acoustic shadow.
Expressed mathematically, the expected measurement for vehicle pose estimate $i$ and timestep $k$ at pixel location $(u,v)$ is:

\begin{equation}
P_k^{i}[u,v] \equiv \text{Prob}(M_k[u,v] = 1)
\label{eq:PM}
\end{equation}

\noindent where $M_k$ is the measured visibility image for timstep $k$ as described in Section \ref{framework.Measurement.Measured}.

The generation of the expected visibility image $P^{i}$ is a major contribution of this work, and is the subject of Chapter \ref{ch.MeasurementModel}.

Figure \ref{fig:expSignals} shows \emph{display} forms of the expected visbility images.  
The form of the actual expected visibility images used for correlation is presented in Section \ref{framework.Measurement.Expected.CorrImage}.
The left image of the figure shows the display expected visibility image for the location where the mechanically-scanned sonar image of Figure \ref{fig:shadowLabeling} was collected (top left image).
The right image of Figure \ref{fig:expSignals} shows the display expected visbility image that corresponds to the sidescan sonar image of Figure \ref{fig:shadowLabeling} (bottom left image).
In the visibility images, red indicates a higher probability of visibility, and blue indicates a lower probability of visibility (i.e. a higher probability that the pixel is in acoustic shadow).

\begin{figure}[!h]
	\centering
	\begin{subfigure}[b]{0.378\textwidth}
                \includegraphics[width=\textwidth]{rvisprobs_561_3}
                \caption{}
  	\end{subfigure}
 	\hspace{5ex}
  	\centering
	\begin{subfigure}[b]{0.545\textwidth}
                \includegraphics[width=\textwidth]{sssSample1_Probs_Hatched}
                \caption{}
  	\end{subfigure}
	\caption{Expected visibility images in \emph{display} form. Red indicates that the pixel has a higher probability of being visible in the measured image. Blue indicates that the pixel has a lower probability of being visible (i.e. higher probability of being in acoustic shadow). The hatched region is outside of the ``Correlation Region'', which is described in Section \ref{framework.Measurement.Expected.Correlation}. }	
	\label{fig:expSignals}
\end{figure}

\subsubsection{Correlation Region}
\label{framework.Measurement.Expected.Correlation}

The non-hatched region of each of the display expected visibility images shown in Figure \ref{fig:expSignals} is the ``Correlation Region'' of the sonar image.
The Correlaton Region is chosen to exclude pixels in the sonar imagery that should not be used for comparison with the measured imagery for state estimation.
The Correlation Region is specified according to one or more of the following factors:

\begin{itemize}
\item \textbf{Minimum Range}. Pixels with range below a specified minimum range are excluded. For example, minimum range can be specified in order to avoid shadows due to non-returns below altitude range, or in order to prevent expected signal computation for ranges where useful shadow information is unlikely.  The right image of Figure \ref{fig:expSignals} is an example of a Non-Correlation Region specified by minimum range.

\item \textbf{Maximum Range}. Pixels with range above a specified maximum range are excluded. For example, pixels with range above the vehicle depth may be discarded in order to prevent corruption of the return data by the water surface.

\item \textbf{Vehicle Self-Shadowing}. Image ranges and azimuths may be excluded to avoid using shadow data that is caused by vehicle self-shadowing.  The left image of Figure \ref{fig:expSignals} is an example of a Non-Correlation Region specified in order to prevent vehicle self-shadowing, where the ROV geometry causes shadows in the corresponding sonar image, as seen in the upper plots of Figure \ref{fig:shadowLabeling}.

\end{itemize}

The expected visibility images used for correlation are presented in the following section, where the Non-Correlation Regions are removed and the polar sonar image format is converted into a horizontal range-azimuth form.

\subsubsection{Correlation Image}
\label{framework.Measurement.Expected.CorrImage}

The expected visibility images used for correlation with measured visibility images take a rectangular range-azimuth form, and contains only Correlation Region pixels.
For sidescan sonar expected visibility imagery, the horizontal range-azimuth form is unchanged.
The main benefit of mapping polar imagery into the horizontal range-azimuth domain is to mitigate the effect of radial information spreading.
That is, for a given angular wedge, the pixel count increases linearly with radius (range) in polar imagery.
If the polar imagery were used for correlation, this would incorrectly weight pixels at higher range more heavily than they should be.

Topograpical map data for Correlation Region azimuth angles and ranges relative to the vehicle pose estimate are used to generate expected visbility imagery.
The details of how the visibility images are generated from map data are left to Chapter \ref{ch.MeasurementModel}.
Figure \ref{fig:expSignalsCORR} presents the expected visibility images used for correlation that correspond to the \emph{display} form imagery of Figure \ref{fig:expSignals}.
Note that the polar imagery is mapped to the horizontal domain according to azimuth angles starting at the vertical and proceeding clockwise to fill the horizontal image from bottom to top.

\begin{figure}[!h]
	\centering
	\begin{subfigure}[b]{0.54\textwidth}
                \includegraphics[width=\textwidth]{rvisprobs_561_3_CORRIMAGE}
                \caption{}
  	\end{subfigure}
 	\hspace{8ex}
  	\centering
	\begin{subfigure}[b]{0.314\textwidth}
                \includegraphics[width=\textwidth]{sssSample1_Probs_CORRIMAGE}
                \caption{}
  	\end{subfigure}
	\caption{Expected visibility images used for correlation with measured visibility images. Red indicates that the pixel has a higher probability of being visible in the measured image. Blue indicates that the pixel has a lower probability of being visible (i.e. higher probability of being in acoustic shadow). (a) Visibility image corresponding to the left \emph{display} form image of Figure \ref{fig:expSignals}. (b) Visbiility image corresponding to the right \emph{display} form image of Figure \ref{fig:expSignals}. }	
	\label{fig:expSignalsCORR}
\end{figure}

\subsection{Measured Shadow Labeling}
\label{framework.Measurement.Measured}

Acoustic shadows in the measured sonar image are assigned a hard label according to image intensity:

\begin{equation}
M[u,v] = \left\{ 
  \begin{array}{l l}
    0 & \quad I[u,v] < \tau \hspace{1ex} \text{(\textbf{measured} shadow)}\\
    1 & \quad \text{otherwise}
  \end{array} \right.
  \label{eq:shadowLabels}
\end{equation}

\noindent where $M$ is the measured visibility image, $I$ is the measured sonar image (intensity image), $(u,v)$ is the pixel index in the image.
Shadows are labeled according to the thresholding of sonar image intensity, where image pixels below the threshold intensity $\tau$ are labeled as shadow.  

Figure \ref{fig:shadowLabeling} presents measured shadow labeling for sample scanning sonar imagery and sidescan sonar imagery.
The left images are the measured sonar images corresponding to the expected visibility images of Figure \ref{fig:expSignalsCORR}.
The top left image was collected by a mechanically-scanned imaging sonar.
The bottom left image was collected by a sidescan sonar. 
The middle images of Figure \ref{fig:shadowLabeling} are the measured visbility images for the corresponding left sonar images in \emph{display} format, akin to the imagery shown in Figure \ref{fig:expSignals}.
The right images are the measured visibility images used for correlation, which are formed in a similar manner to tthe expected visibility images used for correlation, as described in Section \ref{framework.Measurement.Expected.CorrImage}.

\begin{figure}[!h]
  	\centering
	\begin{subfigure}[b]{0.28\textwidth}
                \includegraphics[width=\textwidth]{ms1000_561_3_c_brighter}
                \caption{}
         \end{subfigure}
         \centering
	\begin{subfigure}[b]{0.28\textwidth}
                \includegraphics[width=\textwidth]{meas_shadows_561_3_ver2}
                \caption{}
  	\end{subfigure}
  	\centering
	\begin{subfigure}[b]{0.4\textwidth}
                \includegraphics[width=\textwidth]{meas_shadows_561_3_ver2_CORRIMAGE}
                \caption{}
  	\end{subfigure}
  	
  	\centering
	\begin{subfigure}[b]{0.352\textwidth}
                \includegraphics[width=\textwidth]{sssSample1}
                \caption{}
  	\end{subfigure}
  	\centering
	\begin{subfigure}[b]{0.352\textwidth}
                \includegraphics[width=\textwidth]{sssSample1_Shadows}
                \caption{}
  	\end{subfigure}	
  	\centering
	\begin{subfigure}[b]{0.24\textwidth}
                \includegraphics[width=\textwidth]{sssSample1_Shadows_CORRIMAGE}
                \caption{}
  	\end{subfigure}
  	
	\caption{Measured shadow labeling in scanning sonar imagery and sidescan sonar imagery.  (a) Measured sonar image collected by a mechanically scanned imaging sonar. Range is proportional to radius from the image center. (b) Acoustic visbility image from measured scanned sonar image in \emph{display} form.  Shadows are shown as black pixels, visible returns are white. (c) Acoustic visibility image from measured scanned sonar image mapped into the Correlation Image format as detailed in Sections \ref{framework.Measurement.Expected.Correlation}, \ref{framework.Measurement.Expected.CorrImage}.  (d) Measured sidescan sonar image.  The horizontal axis of the sidescan sonar image is time of flight (or range) and the vertical axis denotes timesteps. (e) Acoustic visibility image from the sidescan sonar image. (f) Acoustic visbility image from sidescan sonar mapped into the Correlation Image format. }	
	\label{fig:shadowLabeling}
\end{figure}

%\subsection{Region-growing and Morphological Image Processing}
%\label{framework.Measured.Region}
%
%Additionally, a region-growing shadow labeling capability has been developed in order to assist the thresholding when it does not properly/cleanly label shadow regions.  The recursive region-growing algorithm takes as input a seed shadow location specified by the user, i.e. ROV operator. A mean intensity value for the shadow region is initialized to the seed pixel intensity. The algorithm then recursively steps outward to the four neighboring pixels and checks two conditions: (1) if the intensity value is within a threshold $\tau_1$ of the seed intensity value, and (2) if the intensity value is within a threshold $\tau_2$ of the mean shadow region intensity.  If a pixel passes these two conditions, the mean intensity value for the region is updated, and the algorithm recursively steps to the untested neighbors of this new shadow pixel location.  Pseudocode for the region-growing algorithm is given below:
%
%\begin{algorithm}
%\caption{Region-growing acoustic shadow labeling}
%\begin{algorithmic}
%\State \textbf{Input: } Sonar intensity image $I$, seed pixel $(u_s, v_s)$
%\State \textbf{Output: } Binary shadow image $M$
%\State \textbf{Initialize: } 
%\State $M[u,v]\gets 1 \hspace{2ex} \forall (u,v) \text{pixels}$
%\State $\alpha \gets I[u_s,v_s] \hspace{2ex} \text{where} \hspace{1ex} \alpha \equiv \text{mean shadow intensity}$
%\State $\beta \gets 1 \hspace{2ex} \text{where} \hspace{1ex} \beta \equiv \text{count of shadow pixels in region}$ 
%\State $\textbf{Call:}$
%\State $M \gets \text{regionGrower}(I,M,u_s,v_s,\alpha,\alpha,\beta)$ \\
%\State \textbf{function} $\text{regionGrower}(I,M,u,v,\gamma,\alpha,\beta)$
%\If {$|I[u,v] - \gamma| \leq \tau_1 \wedge |I[u,v] - \alpha| \leq \tau_2$} 
%\State $\beta \gets \beta + 1$
%\State $\alpha \gets ((\beta-1)\alpha + I[u,v])/\beta$ 
%\State $M[u,v] \gets 0$
%\ForAll {$(u_N,v_N) \in \text{neighbor set of pixel} (u,v)$}
%\State $M \gets \text{regionGrower}(I,M,u_N,v_N,I[u,v],\alpha,\beta)$
%\EndFor
%\EndIf
%\\
%\Return $M$
%\end{algorithmic}
%\label{alg:regionGrow}
%\end{algorithm}

%In order to provide the capability to further clean the shadow detection process, morphological image processing may be employed. The overall effect of the morphological process is to eliminate noisy holes in shadow regions. The image is first eroded, which consists of sliding a structuring element (disk or square) over the image and performing a logical AND of the pixel values over the structuring element.  This has the positive effect of closing shadow holes, with the negative effect of growing shadow region boundaries.  The image is then dilated to compensate for shadow boundary growth, which is the same process as erosion but with a logical OR instead of AND.  Figure \ref{fig:morph} presents a measured shadow image before and after morphological image processing.
%
%\begin{figure}[!h]
%	\centering
%	\begin{subfigure}[b]{0.4\textwidth}
%                \includegraphics[width=\textwidth]{MeasShadows2_raw_c}
%                \caption{Measured Shadow Image before Morphological Processing}
%  	\end{subfigure}
%  	\hspace{10ex}
%  	\centering
%	\begin{subfigure}[b]{0.4\textwidth}
%                \includegraphics[width=\textwidth]{MeasShadows2_c}
%                \caption{Measured Shadow Image after Morphological Processing}
%  	\end{subfigure}
%	\caption{\small Morphological image processing on acoustic shadow images. (a) Raw shadow image labeled by thresholding. (b) Shadow image after morphological image processing.}	
%	\label{fig:morph}
%\end{figure}

\subsection{Measurement Weighting Function}
\label{framework.Measurement.Weighting}

A pose estimate $i$ for timestep $k$, $\mathbf{s}_k^{i}$, is assigned a measurement update weight, $p(\mathbf{z}_k | \mathbf{s}_k^{i}, m)$, according to how well the actual measurement agrees with the expected measurement.
The structure of the measurement update depends on the nature of the measurement and the nature of the estimator.
In this work, the measurement is highly nonlinear, and as such is ill-suited to estimators that require measurement model linearization.
However, there are many estimators that evaluate the agreement of actual measurements with expected measurements from discrete pose estimates, and for these estimators the measurement update presented in this work is appropriate.

As the measurement described in Section \ref{framework.Measurement.Measured} is an image of binary assignments, the measurement update function is derived from a simple relationship with regard to Bernoulli random variables.  Suppose you flip a fair coin once, and want to know the probability that it is heads.  In this case, the chance of heads is $\sfrac{1}{2}$. Now suppose you flip a biased coin, $b \in \{0,1\}$, where the probability of heads is $p$, i.e. $\text{Prob}(b = 1) = p$. In this case, the chance of heads is obviously equal to $p$. Now suppose that another coin $f$ is tossed first, and you want to represent the probability that the biased coin toss equals the first toss, i.e. $\text{Prob}(b=f)$.  In this case, the probability can be represented mathematically as:

\begin{align}
\begin{split}
\text{Prob}(b=f) &= p^{\mathbf{1}\{f=1\}} (1 - p)^{\mathbf{1}\{f=0\}} \\
&= p^{f}(1-p)^{(1-f)}
\end{split}
\label{eq:binaryFlips}
\end{align}

The measurement update introduced in this work is obtained by extending the relationship of Equation \ref{eq:binaryFlips}.
First, the first coin concept is replaced by a pixel in the measured visibility image.
Second, the biased coint concept is replaced by the corresponding pixel in the expected visibility image.
Finally, this ``one flip'' relationship is extended to all of the pixels in the visbility images, where the total agreement probability is the product of all individual pixel agreement probabilities.

The measurement update, $p(\mathbf{z}_k | \mathbf{s}_k^{i}, m)$, is given by Equation \ref{eq:measWeight}:

%\begin{equation}
%p(\mathbf{z}_k | \mathbf{s}_k^{i}, m)  = \prod_{(u,v) \in C}  \underbrace{M_k[u,v]P_k^{i}[u,v]}_{\text{measured visible}} + \underbrace{\left(1 - M_k[u,v]\right)\left(1 - P_k^{i}[u,v]\right)}_{\text{measured shadow}} 
%\label{eq:measWeight}
%\end{equation}
\large
\begin{equation}
p(\mathbf{z}_k | \mathbf{s}_k^{i}, m)  = \prod_{(u,v) \in C} P_k^{i}[u,v]^{M_k[u,v]} (1 - P_k^{i}[u,v])^{(1 - M_k[u,v])}
\label{eq:measWeight}
\end{equation}
\normalsize
\\
\noindent where $M_k$ is the measured visibility image at timestep $k$, $P_k^{i}$ is the expected visibility image for pose estimate $i$ at timestep $k$, and $(u,v)$ index pixel locations in the images.
Term $C$ refers to the pixel domain of the correlation imagery, i.e. the rectangular pixel domain of the correlation images $M_k$, $P_k^{i}$.

%\small
%\begin{align}
%\label{eq:weight1}
%%\begin{split}
%w_0^{(i,j)} &= \prod_{(u,v) \in C}  \underbrace{M[u,v]P[u,v]^{(i,j)}}_{\text{measured visible}} + \underbrace{\left(1 - M[u,v]\right)\left(1 - P[u,v]^{(i,j)}\right)}_{\text{measured shadow}} \\
%w^{(i,j)} &= \frac{w_0^{(i,j)}}{\sum_i \sum_j w_0^{(i,j)}} 
%\label{eq:weight2}
%%\end{split}
%\end{align} 
%\normalsize

\section{Point Mass Filter (PMF)}
\label{framework.PMF}

The preceding sections provided an introduction to the measurement update that is a major contribution of this work.
The measurement update is usable in any Bayesian estimator that does not require measurement model linearization.

Another contribution of this thesis is an estimator design for the use of this measurement update for topography map-relative position localization of underwater robotic vehicles.
The estimator presented in this work is an implementation of a point mass filter (PMF).

A PMF is a non-parametric filter that propagates discrete state estimates in order to model an underlying posterior state distribution.
PMFs have been used extensively in underwater navigation solutions, and are detailed in \cite{Anonsen2006}.  

In this work, the PMF estimated state is horizontal 2-D Northings and Eastings vehicle position $\textbf{x} = [x_{N}, x_{E}]^{T}$, relative a horizontal datum, as overviewed in Section \ref{framework.Underwater}.
The horizontal datum is the best latitude/longitude estimate from either an integrated INS solution or USBL.
Restricting the estimated state space to two dimensions is computationally beneficial, as in general non-parametric state estimation is computationally exponential in the number of states.

%For the ROV platforms used for field data collection in this thesis, an AHRS provides an accurate estimate of vehicle attitude.
%Further, the ROV is capable of maintaining closed-loop control on pitch and roll that keeps those states within a couple of degrees of zero at most.
%Accurate measurement of heading is very important, and is provided by the AHRS.
%
%For the AUV platform used for field data collection in this thesis, a highly accurate Kearfott SEADeVil KN-6083 INS was used for attitude estimation.  
%Noise was added to the INS measurements in order to simulate the use of less accurate inerital navigation systems.
%
%For the experimental systems used in this work, these measurements of the non-estimated vehicle states are sufficiently accurate.
%If this work is used on other experimental systems for which the measurements of these states is not sufficiently accurate, state estimators would need to be used for these states as well.

As with all Bayesian recursive state estimators, a PMF involves two updates: a measurement update, and a motion update.  The measurement update incorporates new sensory data into the state estimate, and the motion update propagates vehicle motion between sensor measurement timesteps.

The following sections detail the PMF initialization (\ref{framework.PMF.Initialization}), the time update (\ref{framework.PMF.Time}), and the measurement update (\ref{framework.PMF.Measurement}).
Section \ref{framework.PMF.MotionCase} describes the specific implementation of the PMF for the case of underwater vehicle motion during measurement collection, which is generally applicable to AUV use with sidescan sonar.
Section \ref{framework.PMF.MotionlessCase} describes the specific implementation of the PMF for the case of an underwater vehicle remaining motionless during measurement collection, which is generally applicable to ROV use with imaging sonar (mechanically-scanned or multibeam).

\subsection{Initialization}
\label{framework.PMF.Initialization}

PMF discrete position estimates $\mathbf{x}_o[i,j]$ are initialized around the best \emph{a priori} absolute position estimate.  
The indices $(i,j)$ reference estimate positions in Easting and Northing dimensions, respectively.
For typical ROV operations, the \emph{a priori} estimate is provided by USBL from the surface vessel.
For AUVs, the \emph{a priori} estimate may be provided by integrated INS odometry from a last absolute posiiton estimate, e.g. a prior GPS surface estimate.
Figure \ref{fig:pmfInit} presents a square initial PMF grid.  The black asterisk is the \emph{a priori} position estimate, and the red circles are the PMF discrete position grid centered about the prior estimate.

\begin{figure}[!h]
	\centering
         \includegraphics[width=0.6\textwidth]{pmfGrid_nocolorbar}
         \caption{PMF initialization grid over a topography DEM. The grid center is the \emph{a priori} position estimate, shown as a black asterisk. The red circles are PMF estimates.  In this case, the grid is $100m$ x $100m$, spaced $5m$.}
	\label{fig:pmfInit}
\end{figure}

The size of the grid, $(N_e, N_n)$, and grid spacing, $\Delta$, are chosen according to the competing objectives of capturing the true state distribution, i.e. covering the true position, and minimizing the computation.
The size of the grid depends on uncertainty from two main sources: (1) error in the \emph{a priori} absolute position estimate, and (2) map geo-referencing error. 

The prior distribution may be specified in a number of ways.
A uniform prior for a rectangular grid may be specified as:

\begin{equation}
p(\mathbf{x}_o^{i}) = \frac{1}{N_e N_n} \hspace{3ex} \forall i \in \text{PMF}
\label{eq:uniformPrior}
\end{equation}

\noindent where $N_e$ and $N_n$ are the grid dimensions in Eastings and Northings, respectively. In this work, uniform priors on rectangular grids will be used primarily, as the prior on geo-referencing error is considered uniform.

If the prior knowledge on vehicle position is considered more informative, then a non-uniform prior may be specified.  A common non-uniform prior is the Gaussian prior, of which a discrete approximation can be formed as follows, assuming uniform grid spacing in both dimensions :

\begin{align}
\begin{split}
p(\mathbf{x}_o^{i,j}) &= \frac {\text{exp}(-\frac{1}{2}(\mathbf{x}_o^{i,j})^{T}\Sigma_o^{-1}\mathbf{x}_o^{i,j})}{\sum_{k=1}^{N_e} \sum_{l=1}^{N_n} \text{exp}(-\frac{1}{2}(\mathbf{x}_o^{k,l})^{T}\Sigma_o^{-1}\mathbf{x}_o^{k,l})}
\end{split}
\label{eq:nonuniformPrior}
\end{align}

For the AUV case of vehicle motion during data collection, usage of both the Gaussian prior and the uniform prior will be compared.  For the motionless case, only the uniform prior is used.

\subsection{Time Update}
\label{framework.PMF.Time}

The PMF time update propagates the state estimation grid deterministically according to the INS vehicle motion estimate, and updates the state distribution probabilities according to estimates of motion noise.
The motion model for the PMF will be modeled as:

\begin{align}
\begin{split}
\tilde{\mathbf{x}}_k^{i,j} &= \mathbf{x}_{k-1}^{i,j} + \mathbf{u}_k + \mathbf{w}_k \\
\mathbf{w}_k &\sim \mathcal{N}(\mathbf{0}, W_k) 
\end{split}
\end{align}

\noindent where $\mathbf{u}_k$ is the integrated INS odometry estimates from timestep $k-1$ to $k$, and $\mathbf{w}_k$ is zero-mean, normally-distributed noise with covariance $W_k$.

The motion update for the PMF may be generically described by:

\begin{align}
\begin{split}
p(\mathbf{x}_k^{(i,j)}|\mathbb{Z}_{k-1}) &= \sum_{q=1}^{N_e} \sum_{r=1}^{N_n} p(\mathbf{x}_k^{(i,j)} | \mathbf{x}_{k-1}^{(q,r)}, \mathbf{u}_k, \mathbf{w}_k) p(\mathbf{x}_{k-1}^{(q,r)}|\mathbb{Z}_{k-1})
\end{split}
\label{eq:pmfMotionUpdate}
\end{align}

The motion update according to Equation \ref{eq:pmfMotionUpdate} is a 2-D convolution.  In this work, the convolution is numerically approximated according to the following procedure:

\begin{enumerate}
\item Propagate the position estimates according to the INS estimate: 

\begin{equation}
\tilde{\mathbf{x}}_k^{i,j} = \mathbf{x}_{k-1}^{i,j} + \mathbf{u}_k
\end{equation}

\noindent where the position distribution is preserved $p(\tilde{\mathbf{x}}_k^{i,j} | \mathbb{Z}_{k-1}) = p(\mathbf{x}_{k-1}^{i,j} | \mathbb{Z}_{k-1})$.

\item Motion noise is propagated through the discrete position distribution by the convolution of the INS-updated distribution $p(\tilde{\mathbf{x}}_k ^{(i,j)}| \mathbb{Z}_{k-1})$ with a discrete noise kernel $K_{W_k}$ with limited support.  The noise kernel in this work is square, with size $(2N_k + 1) \hspace{0.3ex} \text{x} \hspace{0.3ex} (2N_k + 1)$, dependent on the modeled noise covariance $W_k$:

\begin{align}
\begin{split}
p(\mathbf{x}_k^{(i,j)} | \mathbb{Z}_{k-1}) &= \sum_{q=-N_k}^{N_k} \sum_{r=-N_k}^{N_k}  K_{W_k}[q,r] p(\tilde{\mathbf{x}}_k^{(i+q, j+r)} | \mathbb{Z}_{k-1}) \\
\end{split}
\label{eq:pmfTimeUpdate}
\end{align}

\end{enumerate}

\subsection{Measurement Update}
\label{framework.PMF.Measurement}

The PMF measurement update calculates the position estimate posterior distribution by the following procedure:

 \begin{enumerate}
 
 \item For each discrete position estimate, $\mathbf{x}_k[i,j]$, the measurement update function in Equation \ref{eq:measWeight} is evaluated to yield $p(\mathbf{z}_k | \mathbf{x}_k[i,j], m)$. 
 
 \item The un-normalized posterior position estimate weight, $p^{*}(\mathbf{x}_k[i,j] | \mathbb{Z}_k)$, is calculated by multiplication of the time update probability, given by Equation \ref{eq:pmfTimeUpdate}, by the measurement update weight $p(\mathbf{z}_k | \mathbf{x}_k[i,j], m)$:
 
 \begin{align}
 \begin{split}
 p^{*}(\mathbf{x}_k[i,j] | \mathbb{Z}_k) &= p(\mathbf{z}_k | \mathbf{x}_k[i,j], m) p(\mathbf{x}_k[i,j] | \mathbb{Z}_{k-1}) 
 \end{split}
 \label{eq:pmfMeasUn}
 \end{align}
 
 \item The posterior position weights given by Equation \ref{eq:pmfMeasUn} are mapped into probabilities by normalizing the results over the discrete position estimate domain:
 
 \begin{align}
 \begin{split}
 p(\mathbf{x}_k[i,j] | \mathbb{Z}_k) = \frac{p^{*}(\mathbf{x}_k[i,j] | \mathbb{Z}_k)}{\sum_{q=1}^{N_e} \sum_{r=1}^{N_n} p^{*}(\mathbf{x}_k[q,r] | \mathbb{Z}_k)}
 \end{split}
 \label{eq:pmfMeasNormalize}
 \end{align}
 
 \end{enumerate}

\subsection{Multi-Resolution Refinement}
\label{framework.PMF.Multi}

Higher resolution position estimates are instantiated about PMF estimates with posterior probabilities above a threshold.
Multi-resolution estimation allows for fine resolution position estimation in likely areas only, rather than bearing the computational cost of the fine resolution estimation over the entire PMF search area.

The population of fine-resolution grid cells is done through a 4-neighbor connected scheme, shown pictorally in Figure \ref{fig:refinegrid_diagram}.  
The red circles are the fine-resolution grid cells and the blue crosses the coarse-resolution cells.

\begin{figure}[!h]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{RefinedGrid_Diagram}
		\caption{}
		\label{fig:refinegrid_diagram}
	\end{subfigure}
	\hspace{8ex}
	\centering
	\begin{subfigure}[b]{0.415\textwidth}
		\includegraphics[width=\textwidth]{RefinedGrid_Diagram_2}
		\caption{}
		\label{fig:resolution}
	\end{subfigure}
	\caption{Connected 4-neighbor fine-resolution PMF grid cell population schemes.  Blue crosses are coarse-resolution grid cells.  Red circles are fine-resolution grid cells. (a) Refinement about one coarse-resolution estimate. (b) Refinement about two diagonally-adjacent coarse-resolution estimates.  }	
\end{figure}

For this work, the refined estimates are populated with a maximum spatial resolution of 1m. 
This resolution value is a natural choice, given that the topography maps used in this work are meter-resolution DEMs.  
Further, the relationship between coarse- and fine-resolutions is chosen according to a compromise between accuracy and computational burden.  
Figure \ref{fig:resolutionTrend} presents the trend for number of refined estimates that are populated  in the connected 4-neighbor population scheme for one coarse-resolution estimate as a function of the ratio of fine- to coarse-grid resolution.

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\textwidth]{RefinedGrid_ResolutionTrend}
	\caption{Connected 4-neighbor computation trend for one coarse-grid cell subdivision as a function of the ratio of fine-grid resolution to coarse-grid resolution.}
	\label{fig:resolutionTrend}
\end{figure}

The mathematical description of the selection of coarse-resolution cells about which to populate fine-resolution estimates, $\mathbb{R}_k$, and the 4-connected neighbors, $\mathbb{N}_k$, is provided below:

\begin{align}
\begin{split}
\mathbf{x}_k[i,j] &\in \mathbb{R}_k \hspace{1ex} \text{if} \hspace{1ex} p(\mathbf{x}_k[i,j] | \mathbb{Z}_k) \geq \tau_{R} \\
\mathbf{x}_k[p,q] &\in \mathbb{N}_k \hspace{1ex} \text{if} \hspace{1ex} | \mathbf{x}_k[p,q] - \mathbf{x}_k[i,j] | = \Delta \hspace{1ex} \text{for any} \hspace{1ex} \mathbf{x}_k[i,j] \in \mathbb{R}_k \\ \\
&\text{where} \\ \\
\mathbb{R}_k \equiv &\hspace{1ex}\text{set of coarse-resolution position estimates about which} \\
& \text{to populate fine-resolution estimates} \\
\mathbb{N}_k \equiv &\hspace{1ex}\text{set of coarse-resolution estimates that are 4-connection neighbors} \\ 
&\text{to estimates in } \hspace{1ex} \mathbb{R}_k \\
\tau_R \equiv &\hspace{1ex}\text{refinement threshold} \\
\Delta \equiv &\hspace{1ex}\text{coarse-resolution grid spacing (uniform in Eastings and Northings)} \\
\end{split}
\label{eq:Sets}
\end{align}
\\

The total posterior probability weight assigned to fine-resolution cells, $w_r$, is based on the posterior probabilities of the refined estimates and their 4-connected neighbors:

\begin{align}
\begin{split}
w_r &= \sum_{(i,j) \in \mathbb{R}_k} [\hspace{0.5ex} p(\mathbf{x}_k[i,j] | \mathbb{Z}_k) \hspace{0.3ex}] + \frac{1}{2} \sum_{(q,r) \in \mathbb{N}_k}  p(\mathbf{x}_k[q,r] | \mathbb{Z}_k) \\
%w_u &= \sum_{(i,j) \notin \mathbb{R}_k, \mathbb{N}_k} p(\mathbf{x}_k[i,j] | \mathbb{Z}_k) \\
\end{split}
\label{eq:refineWeights}
\end{align}

Fine-resolution position estimates are initialized with uniform priors over the probability mass assigned to the refined coarse-resolution estimates.
Estimation then proceeds on the fine-resolution estimates, where for each fine-resolution estimate, $\mathbf{x}_k^{f}[i]$, a posterior probability, $p(\mathbf{x}_k^{f}[i] | \mathbb{Z}_k)$, is calculated where this is a valid probability that sums to one over the fine-resolution estimates ($ \sum_{i \in \mathbb{X}_F} p(\mathbf{x}_k^{f}[i] | \mathbb{Z}_k) = 1$).

The full (multi-resolution) position posterior distribution is calculated as a weighted combination of the posterior distributions over the fine-resolution estimates, $\mathbb{X}_F$,  the coare-resolution neighbor estimates, $\mathbb{X}_N$, and the non-refined coarse-resolution estimates, $\mathbb{X}_U$ according to:

\begin{align}
\begin{split}
p(\mathbf{x}_k[i] | \mathbb{Z}_k) = \left\{ 
  \begin{array}{l l}
    w_r p(\mathbf{x}_k^{f}[i] | \mathbb{Z}_k) & \quad \text{if $\mathbf{x}_k[i] \in \mathbb{X}_F$} \\
    \frac{1}{2} p(\mathbf{x}_k[i] | \mathbb{Z}_k) & \quad \text{if $\mathbf{x}_k[i] \in \mathbb{X}_N$} \\
    p(\mathbf{x}_k[i] | \mathbb{Z}_k) & \quad \text{otherwise}
  \end{array} \right.
\end{split}
\label{eq:posteriorProb}
\end{align}

\subsection{Operation with Vehicle Motion}
\label{framework.PMF.MotionCase}

\subsection{Operation without Vehicle Motion}
\label{framework.PMF.MotionlessCase}

In the motionless case, the underwater vehicle is not moving during sensory measurements.
In this case, there are no motion updates in the PMF.
Further, in this work a uniform prior over discrete position estimates is assumed according to Equation \ref{eq:uniformPrior}.
With a uniform prior and no motion updates, the estimation reduces to a maximum likelihood (ML) estimator:

\begin{equation}
\mathbf{x}_{MLE} = \underset{\mathbf{x}}{\text{argmax}} \hspace{1ex} \prod_{k=1}^{K} p(\mathbf{z}_k | \mathbf{x}, m)
\label{eq:ML}
\end{equation}

\noindent where $p(\mathbf{z}_k | \mathbf{x}, m)$ is specified by Equation \ref{eq:measWeight}. 
The maximum likelihood estimate (MLE) is the peak in the estimated probability distribution.

Figure \ref{fig:estDiagram} provides a pictoral overview of the localization method for the motionless case.   
Initially, a rectangular grid of position estimates is instantiated about the USBL-estimated ROV position at a coarse resolution.  
In this work, the coarse resolution is $5m$.
For each position estimate, an expected measurement is generated, as overviewed in Section \ref{framework.Measurement}.
This expected measurement is correlated with actual measurements according to measurement update, described in Sections \ref{framework.Measurement.Weighting}, \ref{framework.PMF.Measurement}.

\begin{figure}[!h]
	\centering
		\includegraphics[width=1.0\textwidth]{EstimationFlowchart_linear}
	\caption{Localization method overview diagram. }
	\label{fig:estDiagram}
\end{figure}

A multi-resolution filtering approach is employed to efficiently estimate ROV position, as overviewed in Section \ref{framework.PMF.Multi}. 

\section{Estimate Statistics}
\label{framework.Statistics}

\subsection{Entropy}
\label{framework.Statistics.Entropy}

Entropy is used in this work as a measure of the uncertainty in the position posterior probability distribution.
Entropy in information theory was introduced in the seminal work of Shannon \cite{shannon1948mathematical}.
Shannon, in the context of signal communication, presented entropy as the average information (bits) needed to code a signal.
Entropy in this work is given by the following relation:

\begin{equation}
H(\mathbb{X}_k | \mathbb{Z}_k) = - \sum_{i=1}^{N_e} \sum_{j=1}^{N_n} p(\mathbf{x}_k[i,j] | \mathbb{Z}_k) \text{log} ( p(\mathbf{x}_k[i,j] | \mathbb{Z}_k) )
\label{eq:entropy}
\end{equation}

\noindent where the natural logarithm is used int his work, and entropy is thus expressed in units of ``nats''.  
In information theory, entropy is often expressed using a base-2 logarithm such that the entropy can be interpreted as the average number of bits needed to encode the information signal.
In this work, the choice of logarithm base is somewhat arbitrary, and there is an equivalence between entropy with the different logarithm base choices according to $H_{\text{nats}} = \text{log}(2) H_{\text{bits}}$.

A higher entropy, $H(\mathbb{X}_k | \mathbb{Z}_k)$, indicates a distribution that is more uncertain.
In particular, a high entropy is a strong indicator that the estimate should not be trusted.

Entropy as a measure of estimator uncertainty is well-suited to non-parametric, often multi-modal position distributions.
Entropy according to Equation \ref{eq:entropy} makes no assumptions on the form of the probability distribution.
Thus, a multi-peaked distribution is just as naturally described by entropy as a Gaussiand distribution.
While this flexibility is a feature, it also has a weakness.
The spread of the distribution in the position domain is not modeled by entropy.
That is, a distribution of four peaks in the center of the position grid has the same entropy as the same four peaks at the four corners of the position grid.
The following section describes another class of statistics suitable for multi-modal distributions that takes probability spread in the position domain into account.

\subsection{Probability Mass about the Posterior Mode (MLE)}
\label{framework.Statistics.Probability}

Another type of non-parametric statistic that can be used to quantify estimator confidence is the posterior probability mass within some distance of the posterior mode.
The mode is the most probable position estimate in the distribution, i.e. the tallest peak.
In maximum likelihood estimation, the mode is referred to as the Maximum Likelihood Estimate (MLE).
In Bayesian estimation (particularly with an informative prior), the mode is referred to as the Maximum A Posteriori (MAP) estimate.
The probability mass within some given distance of the mode is a measure of how tightly probability mass is grouped around the mode.
In this work, and in addition to entropy, this statistic is used as a means of quantifying estimator uncertainty in the mode estimate.

The ``mass within $x$'' statistic, $\alpha_\emph{x}$, is now defined as the posterior probability mass within $x$ distance (meters) of the posterior mode (MAP or MLE):

\begin{equation}
\alpha_\emph{x} \equiv \sum_{i=1}^{N} \mathbf{1}\{ | \mathbf{x}[i] - \mathbf{x}_{\text{MLE}} | \leq \emph{x}\} p(\mathbf{x}[i] | \mathbb{Z})
\label{eq:alpha}
\end{equation}

For example, $\alpha_5$ is the probability mass within $5m$ of the posterior mode (including the posterior mode probability).

\subsection{First and Second Moments}
\label{framework.Statistics.Moments}

The posterior distribution first and second moments (mean and covariance matrix, respectively) are estimated by:


\begin{align}
\begin{split}
\hat{\textbf{x}_k} &= \sum_{i=1}^{N_N}\sum_{j=1}^{N_E}\begin{bmatrix} x_{N}(i) \\ x_{E}(j) \end{bmatrix} p(\mathbf{x}_k[i,j] | \mathbb{Z}_k) \\
\Sigma_k &= \sum_{i=1}^{N_N}\sum_{j=1}^{N_E}\left(\begin{bmatrix} x_{N}(i) \\ x_{E}(j) \end{bmatrix} - \hat{\textbf{x}}\right)\left(\begin{bmatrix} x_{N}(i) \\ x_{E}(j) \end{bmatrix} - \hat{\textbf{x}}\right)^{T} p(\mathbf{x}_k[i,j] | \mathbb{Z}_k) \\
&= \begin{bmatrix} \sigma_N^{2} & \sigma_{NE} \\ \sigma_{NE} & \sigma_E^{2} \end{bmatrix}
\label{eq:meanCov}
\end{split}
\end{align}

The covariance matrix is useful for evaluation of the filter confidence.
In particular, standard deviations in Northings, $\sigma_N$, and Eastings, $\sigma_E$, are tabulated for experimental results as a means of quantifying filter confidence.
The root determinant of covariance, termed ``rdc'' in this work, is a single scalar statistic derived from the covariance matrix that is useful for quantifying filter confidence:

\begin{equation}
\text{rdc} \equiv \sqrt{| \Sigma_k | } = \sqrt{ \sigma_N^{2} \sigma_E^{2} - \sigma_{NE}^{2} }
\end{equation}

While these statistics based on the second moment of the distribution are useful as measures of estimator confidence, they are ill-suited to summarizing the distribution for multi-modal position distributions, which are often encountered in localization.

\subsection{Peak Estimation}
\label{framework.Statistics.Peak}

\subsection{Similarity Score}
\label{framework.Statistics.Similarity}
